{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188c2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext import data, datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "# Let's use simple Naive Bayes Classification\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "vectorizer = CountVectorizer()\n",
    "classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6233d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=IMDB(split=\"train\")\n",
    "testing_set=IMDB(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1b8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_texts  = []\n",
    "valid_texts  = []\n",
    "valid_labels = []\n",
    "####################\n",
    "train_text_pos = []\n",
    "train_label_pos = []\n",
    "train_text_neg = []\n",
    "train_label_neg = []\n",
    "for label, text in training_set:\n",
    "  if label == 'pos':\n",
    "    train_label_pos.append(1)\n",
    "    train_text_pos.append(text)\n",
    "  else:\n",
    "    train_label_neg.append(0)\n",
    "    train_text_neg.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc9a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_texts=train_text_pos[0:2500]+train_text_neg[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c8aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels=train_label_pos[0:2500]+train_label_neg[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd70087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts=train_text_pos[2500:]+train_text_neg[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0acb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_label_pos[2500:]+train_label_neg[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e2d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_texts = []\n",
    "for label, text in testing_set:\n",
    "  if label == 'pos':\n",
    "    test_labels.append(1)\n",
    "  else:\n",
    "    test_labels.append(0)\n",
    "  test_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff267d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame({'review': train_texts, 'label':train_labels})\n",
    "df_valid=pd.DataFrame({'review': valid_texts, 'label':valid_labels})\n",
    "df_test=pd.DataFrame({'review': test_texts, 'label':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e43f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus =train_texts+valid_texts+test_texts\n",
    "label =train_labels+valid_labels+test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bcb69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887b219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews=list()\n",
    "for text in corpus:\n",
    "  text = text.lower()\n",
    "  text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "  all_reviews.append(text)\n",
    "all_text = \" \".join(all_reviews)\n",
    "all_words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "053e3425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten occuring words :  [('the', 663815), ('and', 320663), ('a', 320517), ('of', 288382), ('to', 266773), ('is', 210161), ('in', 184861), ('it', 152899), ('i', 152092), ('this', 149405)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(all_words)\n",
    "total_words=len(all_words)\n",
    "sorted_words=count_words.most_common(total_words)\n",
    "print(\"Top ten occuring words : \",sorted_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a75671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11512912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2359ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181685"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991273d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n",
    "print(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4af4e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'budget limitations time restrictions shooting a script and then cutting it cutting it cutting it this crew is a group of good young filmmakers thoughtful in this script  yes allegorical  clever in zerodollar effects when time and knowledge is all you have relying on actors and friends and kind others for their time devotion locations and getting a first feature in the can a 1in1000 thing these guys make films good ones check out their shorts collection heartland horrors and see the development and i can vouch working with them is about the most fun thing youll do in the business im stymied by harsh insulting criticism for this film wondering if one reviewer even heard one word of dialogue pondered one thought or concept or if all that was desired of this work was the visual gore of bashing and slashing to satisfy some mindless view of what horror should mean to an audience let the empty acre bring itself to you dont preconceive what you expect it should be just because it gets put in the horrorthriller genre due to its supernatural premise its a drama with depth beyond how far you can stick a blade into someone with a reverence for a message that doesnt assault your brains visual center but rather draws upon ones empathetic imagination to experience others suffering of mind and spirit mark ridgway curtis the empty acre'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "395dde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_reviews=list()\n",
    "for review in all_reviews:\n",
    "  encoded_review=list()\n",
    "  for word in review.split():\n",
    "    if word not in vocab_to_int.keys():\n",
    "      #if word is not available in vocab_to_int put 0 in that place\n",
    "      encoded_review.append(0)\n",
    "    else:\n",
    "      encoded_review.append(vocab_to_int[word])\n",
    "  encoded_reviews.append(encoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62ded0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[395,\n",
       " 6232,\n",
       " 59,\n",
       " 13664,\n",
       " 1190,\n",
       " 3,\n",
       " 229,\n",
       " 2,\n",
       " 90,\n",
       " 2461,\n",
       " 8,\n",
       " 2461,\n",
       " 8,\n",
       " 2461,\n",
       " 8,\n",
       " 10,\n",
       " 880,\n",
       " 6,\n",
       " 3,\n",
       " 529,\n",
       " 4,\n",
       " 49,\n",
       " 182,\n",
       " 894,\n",
       " 4291,\n",
       " 7,\n",
       " 10,\n",
       " 229,\n",
       " 420,\n",
       " 15378,\n",
       " 1019,\n",
       " 7,\n",
       " 81744,\n",
       " 287,\n",
       " 50,\n",
       " 59,\n",
       " 2,\n",
       " 1796,\n",
       " 6,\n",
       " 31,\n",
       " 22,\n",
       " 25,\n",
       " 8330,\n",
       " 20,\n",
       " 150,\n",
       " 2,\n",
       " 333,\n",
       " 2,\n",
       " 236,\n",
       " 379,\n",
       " 16,\n",
       " 63,\n",
       " 59,\n",
       " 7893,\n",
       " 1782,\n",
       " 2,\n",
       " 369,\n",
       " 3,\n",
       " 87,\n",
       " 811,\n",
       " 7,\n",
       " 1,\n",
       " 68,\n",
       " 3,\n",
       " 81745,\n",
       " 146,\n",
       " 126,\n",
       " 409,\n",
       " 94,\n",
       " 95,\n",
       " 49,\n",
       " 517,\n",
       " 815,\n",
       " 45,\n",
       " 63,\n",
       " 2676,\n",
       " 1516,\n",
       " 18404,\n",
       " 3381,\n",
       " 2,\n",
       " 64,\n",
       " 1,\n",
       " 980,\n",
       " 2,\n",
       " 9,\n",
       " 68,\n",
       " 27652,\n",
       " 778,\n",
       " 15,\n",
       " 93,\n",
       " 6,\n",
       " 42,\n",
       " 1,\n",
       " 86,\n",
       " 246,\n",
       " 146,\n",
       " 461,\n",
       " 78,\n",
       " 7,\n",
       " 1,\n",
       " 967,\n",
       " 141,\n",
       " 45598,\n",
       " 32,\n",
       " 2409,\n",
       " 3799,\n",
       " 2766,\n",
       " 16,\n",
       " 10,\n",
       " 19,\n",
       " 1490,\n",
       " 43,\n",
       " 28,\n",
       " 2175,\n",
       " 54,\n",
       " 537,\n",
       " 28,\n",
       " 670,\n",
       " 4,\n",
       " 405,\n",
       " 45599,\n",
       " 28,\n",
       " 194,\n",
       " 39,\n",
       " 1119,\n",
       " 39,\n",
       " 43,\n",
       " 31,\n",
       " 11,\n",
       " 13,\n",
       " 4629,\n",
       " 4,\n",
       " 10,\n",
       " 163,\n",
       " 13,\n",
       " 1,\n",
       " 1039,\n",
       " 635,\n",
       " 4,\n",
       " 7650,\n",
       " 2,\n",
       " 14469,\n",
       " 5,\n",
       " 4823,\n",
       " 46,\n",
       " 2955,\n",
       " 655,\n",
       " 4,\n",
       " 48,\n",
       " 193,\n",
       " 139,\n",
       " 383,\n",
       " 5,\n",
       " 33,\n",
       " 307,\n",
       " 367,\n",
       " 1,\n",
       " 1937,\n",
       " 23503,\n",
       " 711,\n",
       " 389,\n",
       " 5,\n",
       " 22,\n",
       " 89,\n",
       " 81746,\n",
       " 48,\n",
       " 22,\n",
       " 507,\n",
       " 8,\n",
       " 139,\n",
       " 26,\n",
       " 40,\n",
       " 83,\n",
       " 8,\n",
       " 204,\n",
       " 264,\n",
       " 7,\n",
       " 1,\n",
       " 13015,\n",
       " 538,\n",
       " 668,\n",
       " 5,\n",
       " 29,\n",
       " 2425,\n",
       " 837,\n",
       " 29,\n",
       " 3,\n",
       " 476,\n",
       " 15,\n",
       " 1147,\n",
       " 648,\n",
       " 85,\n",
       " 224,\n",
       " 22,\n",
       " 68,\n",
       " 1234,\n",
       " 3,\n",
       " 3295,\n",
       " 81,\n",
       " 285,\n",
       " 15,\n",
       " 3,\n",
       " 16371,\n",
       " 16,\n",
       " 3,\n",
       " 743,\n",
       " 11,\n",
       " 148,\n",
       " 4607,\n",
       " 122,\n",
       " 3764,\n",
       " 1039,\n",
       " 2191,\n",
       " 18,\n",
       " 241,\n",
       " 3765,\n",
       " 672,\n",
       " 517,\n",
       " 19962,\n",
       " 1571,\n",
       " 5,\n",
       " 558,\n",
       " 379,\n",
       " 2259,\n",
       " 4,\n",
       " 337,\n",
       " 2,\n",
       " 1150,\n",
       " 961,\n",
       " 81747,\n",
       " 4292,\n",
       " 1,\n",
       " 1937,\n",
       " 23503]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ff0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "this step will Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "'''\n",
    "sequence_length=250\n",
    "features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "for i, review in enumerate(encoded_reviews):\n",
    "  review_len=len(review)\n",
    "  if (review_len<=sequence_length):\n",
    "    zeros=list(np.zeros(sequence_length-review_len))\n",
    "    new=zeros+review\n",
    "  else:\n",
    "    new=review[:sequence_length]\n",
    "  features[i,:]=np.array(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06832414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
    "train_x=features[:int(0.8*len(features))]\n",
    "train_y=label[:int(0.8*len(features))]\n",
    "valid_x=features[int(0.8*len(features)):int(0.9*len(features))]\n",
    "valid_y=label[int(0.8*len(features)):int(0.9*len(features))]\n",
    "test_x=features[int(0.9*len(features)):]\n",
    "test_y=label[int(0.9*len(features)):]\n",
    "print(len(train_y), len(valid_y), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d1b26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#create Tensor Dataset\n",
    "train_data=TensorDataset(torch.LongTensor(train_x), torch.LongTensor(train_y))\n",
    "valid_data=TensorDataset(torch.LongTensor(valid_x), torch.LongTensor(valid_y))\n",
    "test_data=TensorDataset(torch.LongTensor(test_x), torch.LongTensor(test_y))\n",
    "\n",
    "#dataloader\n",
    "batch_size=32\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44a0f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([32, 250])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,    70,   232,   327],\n",
      "        [ 3373,     1,   251,  ...,   124,     7,    97],\n",
      "        [    9,    40,   201,  ...,  2372,    46,  4188],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    20,   344,   386],\n",
      "        [    0,     0,     0,  ..., 66541,    12, 97796],\n",
      "        [  420,    29,   152,  ...,    30,    31,    50]])\n",
      "Sample label size:  torch.Size([32])\n",
      "Sample label: \n",
      " tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60100274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    " \n",
    "class SentimentalLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        #Embedding and LSTM layers\n",
    "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        #dropout layer\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "        \n",
    "        #Linear and sigmoid layer\n",
    "        self.fc1=nn.Linear(hidden_dim, 64)\n",
    "        self.fc2=nn.Linear(64, 16)\n",
    "        self.fc3=nn.Linear(16,output_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size=x.size()\n",
    "        \n",
    "        #Embadding and LSTM output\n",
    "        embedd=self.embedding(x)\n",
    "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
    "        \n",
    "        #stack up the lstm output\n",
    "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        #dropout and fully connected layers\n",
    "        out=self.dropout(lstm_out)\n",
    "        out=self.fc1(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc3(out)\n",
    "        sig_out=self.sigmoid(out)\n",
    "        \n",
    "        sig_out=sig_out.view(batch_size, -1)\n",
    "        sig_out=sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f22726f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentalLSTM(\n",
      "  (embedding): Embedding(181686, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput:\\n SentimentalLSTM(   \\n(embedding): Embedding(74073, 400)   \\n(lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)   (dropout): Dropout(p=0.3)   \\n(fc): Linear(in_features=256, out_features=1, bias=True)   (sigmoid): Sigmoid() )\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)\n",
    "\n",
    "'''\n",
    "Output:\n",
    " SentimentalLSTM(   \n",
    "(embedding): Embedding(74073, 400)   \n",
    "(lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)   (dropout): Dropout(p=0.3)   \n",
    "(fc): Linear(in_features=256, out_features=1, bias=True)   (sigmoid): Sigmoid() )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f026a468",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 5.81 GiB total capacity; 1.11 GiB already allocated; 68.62 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# move model to GPU, if available\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(train_on_gpu):\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 5.81 GiB total capacity; 1.11 GiB already allocated; 68.62 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "# training params\n",
    "\n",
    "epochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "# net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "126c8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "del net\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75372bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentalLSTM(\n",
       "  (embedding): Embedding(181686, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ecb140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 5.81 GiB total capacity; 1.11 GiB already allocated; 78.94 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(net\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[0;32m---> 28\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# loss stats\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Get validation loss\u001b[39;00m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_env/lib/python3.8/site-packages/torch/optim/adam.py:307\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    309\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 5.81 GiB total capacity; 1.11 GiB already allocated; 78.94 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()  \n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fe279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79b93694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d41bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4fd5184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13bde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7e041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8e8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
