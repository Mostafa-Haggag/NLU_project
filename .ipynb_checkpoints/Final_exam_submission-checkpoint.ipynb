{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75ae5d9",
   "metadata": {},
   "source": [
    "* movie reviews NLTK movie_reviews\n",
    "* subjectivitiydataset: nltk subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38abead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext import data, datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "# Let's use simple Naive Bayes Classification\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "vectorizer = CountVectorizer()\n",
    "classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d015e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# nlp.add_pipe(\"sentencizer\")\n",
    "# print(nlp.pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767b4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 5\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d684c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=IMDB(split=\"train\")\n",
    "testing_set=IMDB(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "befbd20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a7b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_texts  = []\n",
    "valid_texts  = []\n",
    "valid_labels = []\n",
    "####################\n",
    "train_text_pos = []\n",
    "train_label_pos = []\n",
    "train_text_neg = []\n",
    "train_label_neg = []\n",
    "for label, text in training_set:\n",
    "  if label == 'pos':\n",
    "    train_label_pos.append(1)\n",
    "    train_text_pos.append(text)\n",
    "  else:\n",
    "    train_label_neg.append(0)\n",
    "    train_text_neg.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_texts=train_text_pos[0:2500]+train_text_neg[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9006189",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels=train_label_pos[0:2500]+train_label_neg[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e49f5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts=train_text_pos[2500:]+train_text_neg[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8de187",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=train_label_pos[2500:]+train_label_neg[2500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76639578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6584a408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d2ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_texts = []\n",
    "for label, text in testing_set:\n",
    "  if label == 'pos':\n",
    "    test_labels.append(1)\n",
    "  else:\n",
    "    test_labels.append(0)\n",
    "  test_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df85619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d6c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame({'review': train_texts, 'label':train_labels})\n",
    "df_valid=pd.DataFrame({'review': valid_texts, 'label':valid_labels})\n",
    "df_test=pd.DataFrame({'review': test_texts, 'label':test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab09dede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>I loved this movie. I knew it would be chocked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>During a Kurt Weill celebration in Brooklyn, W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>I really enjoyed this movie. The script is fre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>I'm gonna tip the scales here a bit and say I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>I am decidedly not in the target audience for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>When i got this movie free from my job, along ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19883</th>\n",
       "      <td>No spoilers here but I have been a fan since W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19884</th>\n",
       "      <td>I feel like I've just watched a snuff film.......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19885</th>\n",
       "      <td>I absolutely hate this programme, what kind of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19968</th>\n",
       "      <td>Sondra Locke stinks in this film, but then she...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "644    I loved this movie. I knew it would be chocked...      1\n",
       "1812   During a Kurt Weill celebration in Brooklyn, W...      1\n",
       "1821   I really enjoyed this movie. The script is fre...      1\n",
       "3158   I'm gonna tip the scales here a bit and say I ...      1\n",
       "3624   I am decidedly not in the target audience for ...      1\n",
       "...                                                  ...    ...\n",
       "19810  When i got this movie free from my job, along ...      0\n",
       "19883  No spoilers here but I have been a fan since W...      0\n",
       "19884  I feel like I've just watched a snuff film.......      0\n",
       "19885  I absolutely hate this programme, what kind of...      0\n",
       "19968  Sondra Locke stinks in this film, but then she...      0\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.duplicated()] # we have 77 item duplicated out of 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45df12ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>The movie was very good. I'm an avid mystery f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>I've been strangely attracted to this film sin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>I was fortunate to attend the London premier o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>A truly excellent look at the world and the re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>Robert Jordan is a television star. Robert Jor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24146</th>\n",
       "      <td>Poorly acted, poorly written and poorly direct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24147</th>\n",
       "      <td>Ed Wood rides again. The fact that this movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24266</th>\n",
       "      <td>This movie looked like it was rushed to releas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>I kind of like JAG. It do have it´s charm but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24857</th>\n",
       "      <td>A friend and I went to see this movie. We have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "861    The movie was very good. I'm an avid mystery f...      1\n",
       "908    I've been strangely attracted to this film sin...      1\n",
       "919    I was fortunate to attend the London premier o...      1\n",
       "1510   A truly excellent look at the world and the re...      1\n",
       "1520   Robert Jordan is a television star. Robert Jor...      1\n",
       "...                                                  ...    ...\n",
       "24146  Poorly acted, poorly written and poorly direct...      0\n",
       "24147  Ed Wood rides again. The fact that this movie ...      0\n",
       "24266  This movie looked like it was rushed to releas...      0\n",
       "24401  I kind of like JAG. It do have it´s charm but ...      0\n",
       "24857  A friend and I went to see this movie. We have...      0\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.duplicated()] # we 199 itmes duplicates out of 25k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d54b65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>A have a female friend who is currently being ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>This movie surprised me. Some things were \"cli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>Wow! So much fun! Probably a bit much for norm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>I Enjoyed Watching This Well Acted Movie Very ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>Smallville episode Justice is the best episode...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>I am not so much like Love Sick as I image. Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>Holy freaking God all-freaking-mighty. This mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>The story and the show were good, but it was r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  label\n",
       "763   A have a female friend who is currently being ...      1\n",
       "924   This movie surprised me. Some things were \"cli...      1\n",
       "947   Wow! So much fun! Probably a bit much for norm...      1\n",
       "1380  I Enjoyed Watching This Well Acted Movie Very ...      1\n",
       "1642  Smallville episode Justice is the best episode...      1\n",
       "2668  I am not so much like Love Sick as I image. Fi...      0\n",
       "3164  Holy freaking God all-freaking-mighty. This mo...      0\n",
       "3201  The story and the show were good, but it was r...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[df_valid.duplicated()] # we have 8 item duplicated out of 2.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241b0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = MultinomialNB()\n",
    "classifier_SVM = SVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53675cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus =train_texts+valid_texts+test_texts\n",
    "label =train_labels+valid_labels+test_labels\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "train_vectors = vectors[:len(train_texts)]\n",
    "valid_vectors = vectors[len(train_texts):len(train_texts)+len(valid_texts)]\n",
    "test_vectors = vectors[len(train_texts)+len(valid_texts):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e70822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 101895)\n",
      "(5000, 101895)\n",
      "(25000, 101895)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(valid_vectors.shape)\n",
    "print(test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "161b1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(classifier, vectors, label, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "print(round(average, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea4bf520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_validate(classifier_SVM, vectors, label, cv=StratifiedKFold(n_splits=10) , scoring=['f1_micro'])\n",
    "# average = sum(scores['test_f1_micro'])/len(scores['test_f1_micro'])\n",
    "# print(round(average, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081bb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ba706b0",
   "metadata": {},
   "source": [
    "## Baseline Vader for document level sentiment polarity classifcation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf7b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer, VaderConstants\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2828c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.779     0.537     0.636     10000\n",
      "           1      0.647     0.848     0.734     10000\n",
      "\n",
      "    accuracy                          0.692     20000\n",
      "   macro avg      0.713     0.692     0.685     20000\n",
      "weighted avg      0.713     0.692     0.685     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = [analyzer.polarity_scores(docs) for docs in train_texts]\n",
    "labels = [(0 if s.get(\"compound\")<0 else 1)for s in scores]\n",
    "print(classification_report(train_labels, labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6900433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.793     0.536     0.640     12500\n",
      "           1      0.650     0.860     0.740     12500\n",
      "\n",
      "    accuracy                          0.698     25000\n",
      "   macro avg      0.722     0.698     0.690     25000\n",
      "weighted avg      0.722     0.698     0.690     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = [analyzer.polarity_scores(docs) for docs in test_texts]\n",
    "labels = [(0 if s.get(\"compound\")<0 else 1)for s in scores]\n",
    "print(classification_report(test_labels, labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d482aa",
   "metadata": {},
   "source": [
    "# second data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81a83809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the movie begins in the past where a young boy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emerging from the human psyche and showing cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spurning her mother's insistence that she get ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amitabh can't believe the board of directors a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>she , among others excentricities , talks to a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  label\n",
       "0  the movie begins in the past where a young boy...      0\n",
       "1  emerging from the human psyche and showing cha...      0\n",
       "2  spurning her mother's insistence that she get ...      0\n",
       "3  amitabh can't believe the board of directors a...      0\n",
       "4  she , among others excentricities , talks to a...      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(path: str):\n",
    "  with open(path, encoding = \"ISO-8859-1\") as file_to_read:\n",
    "    content = np.array(file_to_read.readlines())\n",
    "\n",
    "  return np.array([line.strip().lower() for line in content])\n",
    "objective_df = pd.DataFrame(read_file(\"data/plot.tok.gt9.5000\"),columns=[\"Sentence\"])\n",
    "subjective_df = pd.DataFrame(read_file(\"data/quote.tok.gt9.5000\"),columns=[\"Sentence\"])\n",
    "subjective_df['label'] = 1\n",
    "objective_df['label'] = 0\n",
    "\n",
    "data_df = pd.concat([objective_df, subjective_df], ignore_index=False)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d49f4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(data_df.Sentence, data_df.label,\n",
    "                                                                              test_size=0.3, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c9ae6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49d9b89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191    0\n",
       "4458    0\n",
       "1131    0\n",
       "4562    1\n",
       "1579    1\n",
       "       ..\n",
       "350     0\n",
       "79      0\n",
       "3039    1\n",
       "1936    1\n",
       "640     1\n",
       "Name: label, Length: 7000, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a7ef717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    the movie begins in the past where a young boy...\n",
      "0    smart and alert , thirteen conversations about...\n",
      "Name: Sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(train_sentences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db3a9784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the movie begins in the past where a young boy...\n",
       "0    smart and alert , thirteen conversations about...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f6bfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_preprocessor(text):\n",
    "    \"\"\"\n",
    "    Preprocessor that returns a list of lemmas of a given text.\n",
    "    \n",
    "    Args:\n",
    "        - text: string that contains the text to be preprocessed\n",
    "        \n",
    "    Returns:\n",
    "        - tokens: a list of strings (lemmas)\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "#     tokens = [token.text for token in doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdba7853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with a schizophrenic father , a self - absorb , distant mother , and a shark - like young republican big brother , igby figure there must be a well life out there , and he set out to find it .\n",
      "######output without lemmas#################\n",
      "with a schizophrenic father , a self-absorbed , distant mother , and a shark-like young republican big brother , igby figures there must be a better life out there , and he sets out to find it .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(doc_preprocessor(train_sentences.iloc[5])))\n",
    "##\n",
    "print(\"######output without lemmas#################\")\n",
    "print(train_sentences.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "618370bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the movie begins in the past where a young boy...\n",
       "0    smart and alert , thirteen conversations about...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bca7f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_SUBJ = CountVectorizer(strip_accents=None, lowercase=True,\n",
    "                                 preprocessor=None, tokenizer=doc_preprocessor,\n",
    "                                 stop_words=None, ngram_range=(1,1),\n",
    "                                 binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7bb9b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafahaggag/python_env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(tokenizer=<function doc_preprocessor at 0x7f9e12653670>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_SUBJ.fit(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c40bd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = vectorizer_SUBJ.transform(train_sentences)\n",
    "test_vec  = vectorizer_SUBJ.transform(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34ce7f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7000x14531 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 153666 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35daecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3000x14531 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 62982 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffd5c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_naive_bayes = MultinomialNB()\n",
    "m_naive_bayes.fit(train_vec, train_labels)\n",
    "te_pred = m_naive_bayes.predict(test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e807b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred = m_naive_bayes.predict(test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82437d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   objective       0.94      0.89      0.92      1495\n",
      "  subjective       0.90      0.94      0.92      1505\n",
      "\n",
      "    accuracy                           0.92      3000\n",
      "   macro avg       0.92      0.92      0.92      3000\n",
      "weighted avg       0.92      0.92      0.92      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con_mat = classification_report(test_labels, te_pred, target_names=['objective', 'subjective'])\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59f46652",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_lab = data_df.label\n",
    "subj_vec = vectorizer_SUBJ.transform(data_df.Sentence)\n",
    "subj_classifier = MultinomialNB()\n",
    "subj_classifier.fit(subj_vec, subj_lab)\n",
    "subj_pred = m_naive_bayes.predict(subj_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "058cef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   objective       0.96      0.93      0.95      5000\n",
      "  subjective       0.93      0.97      0.95      5000\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con_mat_sb = classification_report(subj_lab, subj_pred, target_names=['objective', 'subjective'])\n",
    "print(con_mat_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0022d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d5ed54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [34:18, 419kB/s]                              \n",
      "100%|███████████████████████████████▉| 399999/400000 [00:05<00:00, 67493.80it/s]\n"
     ]
    }
   ],
   "source": [
    "global_vectors = GloVe(name='6B', dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09247c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
